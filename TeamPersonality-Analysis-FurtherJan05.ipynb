{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJ0e5UTskI8a"
   },
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3237,
     "status": "ok",
     "timestamp": 1672907655561,
     "user": {
      "displayName": "Nghi Truong",
      "userId": "16652552820501542091"
     },
     "user_tz": -420
    },
    "id": "6hruT9cckIXM",
    "outputId": "33220286-2715-4d92-8d62-7c4d129797df"
   },
   "outputs": [],
   "source": [
    "#import basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import itertools\n",
    "import re\n",
    "import scipy\n",
    "\n",
    "#import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,r2_score,mean_squared_error\n",
    "\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJyxVf2bmWoM"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1672900667747,
     "user": {
      "displayName": "Nghi Truong",
      "userId": "16652552820501542091"
     },
     "user_tz": -420
    },
    "id": "0cJH-fD-mSwa"
   },
   "outputs": [],
   "source": [
    "#import data\n",
    "dat1_with_missing=pd.read_csv(\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Data/TeamPersonality-Data1-full.csv\")\n",
    "dat2_with_missing=pd.read_csv(\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Data/TeamPersonality-Data2-full.csv\")\n",
    "dat1_drop_missing=pd.read_csv(\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Data/TeamPersonality-Data1-refined.csv\")\n",
    "dat2_drop_missing=pd.read_csv(\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Data/TeamPersonality-Data2-refined.csv\")\n",
    "\n",
    "dat1_with_missing=dat1_with_missing.drop(['gender_all_sd','gender_exc_sd','size','size_all','GroupID'],axis=1)\n",
    "dat2_with_missing=dat2_with_missing.drop(['gender_all_sd','gender_exc_sd','size','size_all','teamid'],axis=1)\n",
    "dat1_drop_missing=dat1_drop_missing.drop(['gender_all_sd','gender_exc_sd','size','GroupID'],axis=1)\n",
    "dat2_drop_missing=dat2_drop_missing.drop(['gender_all_sd','gender_exc_sd','size','teamid'],axis=1)\n",
    "\n",
    "dat2_with_missing_names=[re.sub('neur','emos',x) for x in dat2_with_missing.columns]\n",
    "dat2_with_missing.columns=dat2_with_missing_names\n",
    "dat2_with_missing = dat2_with_missing[dat2_with_missing['gender_leader'].notna()]\n",
    "\n",
    "dat2_drop_missing_names=[re.sub('neur','emos',x) for x in dat2_with_missing.columns]\n",
    "dat2_drop_missing.columns=dat2_with_missing_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1iFlH5Ein7Wx"
   },
   "source": [
    "## Define all necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1672900673246,
     "user": {
      "displayName": "Nghi Truong",
      "userId": "16652552820501542091"
     },
     "user_tz": -420
    },
    "id": "uhzOqzALn56S"
   },
   "outputs": [],
   "source": [
    "# OLS to test hypothesis\n",
    "def _alg_linear(X,Y,predictors):\n",
    "    X_min=X[predictors]\n",
    "    X_min = sm.add_constant(X_min)\n",
    "    #fit linear regression model\n",
    "    model = sm.OLS(Y, X_min).fit()\n",
    "    coefs = pd.DataFrame({'Coef':model.params[1:(len(predictors)+1)],'p-value':model.pvalues[1:(len(predictors)+1)]})\n",
    "    coefs['vars']=coefs.index\n",
    "    coefs.index=np.arange(0,len(predictors),1)\n",
    "    overall_eva = pd.DataFrame({'R2':model.rsquared,'R2-adj':model.rsquared_adj,\n",
    "                            'Fvalue':model.fvalue,'Fpvalue':model.f_pvalue,\n",
    "                           'AIC':model.aic,'BIC':model.bic},index=[0])\n",
    "    return coefs,overall_eva\n",
    "\n",
    "## Randomforest with RandomizedSearch\n",
    "def _alg_randomforest(X_train,Y_train,X_test,Y_test,params,cv,n_iter):   \n",
    "    #Create the model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    #search across different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                                 param_distributions = params, \n",
    "                                 n_iter = n_iter, cv = cv, \n",
    "                                 verbose=2, \n",
    "                                 n_jobs = -1,\n",
    "                                 scoring = 'r2')\n",
    "    # Fit the random search model with exc variables\n",
    "    rf_random.fit(X_train,Y_train)\n",
    "    best_params=rf_random.best_params_\n",
    "    best_params_data=pd.DataFrame(best_params,index=[0])\n",
    "    rf_final = RandomForestRegressor(**best_params)\n",
    "    rf_final.fit(X_train,Y_train)\n",
    "    Y_pred=rf_final.predict(X_train)\n",
    "    accuracyA = pd.DataFrame({'R2':r2_score(Y_train,Y_pred),\n",
    "                        'MAE':mean_absolute_error(Y_train,Y_pred),\n",
    "                        'RMSE':np.sqrt(mean_squared_error(Y_train, Y_pred))},index=[0])\n",
    "    features=X_train.columns\n",
    "    f_i = list(zip(features,rf_final.feature_importances_))\n",
    "    f_i.sort(key = lambda x : x[1],reverse=True)\n",
    "    f_i = pd.DataFrame(f_i, columns=['feature', 'score'])\n",
    "    Y_pred=rf_final.predict(X_test)\n",
    "    accuracyB = pd.DataFrame({'R2':r2_score(Y_test,Y_pred),\n",
    "                        'MAE':mean_absolute_error(Y_test,Y_pred),\n",
    "                        'RMSE':np.sqrt(mean_squared_error(Y_test, Y_pred))},index=[0])\n",
    "    return f_i, accuracyA, accuracyB, best_params_data\n",
    "\n",
    "## Randomforest with GridSearch\n",
    "def _alg_randomforest_gridsearch(X_train,Y_train,X_test,Y_test,params,cv):\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_grid = GridSearchCV(estimator = rf, param_grid = params, \n",
    "                           scoring = 'r2', cv = cv, \n",
    "                           n_jobs = -1, verbose = 2)\n",
    "    rf_grid.fit(X_train,Y_train)\n",
    "    best_params=rf_grid.best_params_\n",
    "    best_params_data=pd.DataFrame(best_params,index=[0])\n",
    "    rf_final = RandomForestRegressor(**best_params)\n",
    "    rf_final.fit(X_train,Y_train)\n",
    "    Y_pred=rf_final.predict(X_train)\n",
    "    accuracyA = pd.DataFrame({'R2':r2_score(Y_train,Y_pred),\n",
    "                        'MAE':mean_absolute_error(Y_train,Y_pred),\n",
    "                        'RMSE':np.sqrt(mean_squared_error(Y_train, Y_pred))},index=[0])\n",
    "    features=X_train.columns\n",
    "    f_i = list(zip(features,rf_final.feature_importances_))\n",
    "    f_i.sort(key = lambda x : x[1],reverse=True)\n",
    "    f_i = pd.DataFrame(f_i, columns=['feature', 'score'])\n",
    "    Y_pred=rf_final.predict(X_test)\n",
    "    accuracyB = pd.DataFrame({'R2':r2_score(Y_test,Y_pred),\n",
    "                        'MAE':mean_absolute_error(Y_test,Y_pred),\n",
    "                        'RMSE':np.sqrt(mean_squared_error(Y_test, Y_pred))},index=[0])\n",
    "    return f_i, accuracyA, accuracyB, best_params_data\n",
    "\n",
    "def _alg_NeuralNetwork_RandomizedSearch(X_train,Y_train,X_test,Y_test,params,cv,n_iter,stand):\n",
    "    if (stand==True):\n",
    "        # Get mean and SD from train data\n",
    "        X_mean = X_train.mean(axis=0)\n",
    "        X_std = X_train.std(axis=0)\n",
    "        Y_mean = Y_train.mean(axis=0)\n",
    "        Y_std = Y_train.std(axis=0)\n",
    "        # Standardise data\n",
    "        X_train -= X_mean\n",
    "        X_train /= X_std\n",
    "        X_test -= X_mean\n",
    "        X_test /= X_std\n",
    "        Y_train -= Y_mean\n",
    "        Y_train /= Y_std\n",
    "        Y_test -= Y_mean\n",
    "        Y_test /= Y_std\n",
    "    # neaural network\n",
    "    nn = MLPRegressor(warm_start=True,random_state=0)\n",
    "    nn_random = RandomizedSearchCV(nn,params,n_iter=n_iter,cv=cv,n_jobs=-1,random_state=0)\n",
    "    nn_random.fit(X_train, Y_train)\n",
    "    best_params=nn_random.best_params_\n",
    "    nn_final = MLPRegressor(**best_params)\n",
    "    nn_final.fit(X_train,Y_train)\n",
    "    if (type(best_params['hidden_layer_sizes'])==tuple):\n",
    "        best_params['hidden_layer_sizes']=','.join(str(v) for v in best_params['hidden_layer_sizes'])\n",
    "    best_params_data=pd.DataFrame(best_params,index=[0])\n",
    "    Y_pred=nn_final.predict(X_train)\n",
    "    accuracyA = pd.DataFrame({'R2':r2_score(Y_train,Y_pred),\n",
    "                        'MAE':mean_absolute_error(Y_train,Y_pred),\n",
    "                        'RMSE':np.sqrt(mean_squared_error(Y_train, Y_pred))},index=[0])\n",
    "    Y_pred=nn_final.predict(X_test)\n",
    "    accuracyB = pd.DataFrame({'R2':r2_score(Y_test,Y_pred),\n",
    "                        'MAE':mean_absolute_error(Y_test,Y_pred),\n",
    "                        'RMSE':np.sqrt(mean_squared_error(Y_test, Y_pred))},index=[0])\n",
    "    return accuracyA, accuracyB, best_params_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test theoretical hypotheses with linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtmfdON5l0aT"
   },
   "source": [
    "## Effect of team's mean personality score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors_set=[['open_all_mean'],['extr_all_mean'],\n",
    "                ['extr_all_mean','open_all_mean'],\n",
    "                ['emos_all_mean','extr_all_mean','open_all_mean', 'agree_all_mean', 'cons_all_mean']]\n",
    "data_set=['drop','full']\n",
    "combinations=list(itertools.product(data_set,predictors_set))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "\n",
    "## create empty full data\n",
    "coefs_all = pd.DataFrame(columns=['Coef','p-value','vars','ID','data','predictors_set'])\n",
    "overall_eva_all = pd.DataFrame(columns=['R2','R2-adj','Fvalue','Fpvalue','AIC','BIC',\n",
    "                                        'ID','data','predictors_set'])\n",
    "\n",
    "## run the models\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load the data\n",
    "    if spec[0]=='drop':\n",
    "        dat=dat1_drop_missing\n",
    "    else:\n",
    "        dat=dat1_with_missing\n",
    "    # load predictor variables\n",
    "    predictors=spec[1]\n",
    "    # create X and Y\n",
    "    X=dat\n",
    "    Y=dat['performance']\n",
    "    # run the model\n",
    "    model=_alg_linear(X,Y,predictors)\n",
    "    # get coefs and evaluation indices\n",
    "    coefs=model[0]\n",
    "    overall_eva=model[1]\n",
    "    # add model specification\n",
    "    coefs['ID']=i\n",
    "    coefs['data']=spec[0]\n",
    "    coefs['predictors_set']=len(predictors)\n",
    "    overall_eva['ID']=i\n",
    "    overall_eva['data']=spec[0]\n",
    "    overall_eva['predictors_set']=len(predictors)\n",
    "    # add to the full data\n",
    "    coefs_all = pd.concat([coefs_all,coefs],ignore_index=True)\n",
    "    overall_eva_all = pd.concat([overall_eva_all,overall_eva],ignore_index=True)\n",
    "\n",
    "## save results\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-TeamPersonality-Coefs-AllObs.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  coefs_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-TeamPersonality-ModelEva-AllObs.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  overall_eva_all.to_csv(f)\n",
    "\n",
    "print(coefs_all)\n",
    "print(overall_eva_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['data']=='drop')]['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['data']=='drop')]['R2-adj']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate over different subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 368,
     "status": "ok",
     "timestamp": 1672901481482,
     "user": {
      "displayName": "Nghi Truong",
      "userId": "16652552820501542091"
     },
     "user_tz": -420
    },
    "id": "YuRx6u3EmR2D",
    "outputId": "557e6f52-33a3-41df-ea75-b4a08cb2a9be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors_set=[['open_all_mean'],['extr_all_mean'],\n",
    "                ['extr_all_mean','open_all_mean'],\n",
    "                ['emos_all_mean','extr_all_mean','open_all_mean', 'agree_all_mean', 'cons_all_mean']]\n",
    "data_set=['drop','full']\n",
    "randomstate_list=list(range(1,101))\n",
    "testsize=[0.5,0.4,0.3,0.2]\n",
    "combinations=list(itertools.product(data_set,predictors_set,randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "\n",
    "## create empty full data\n",
    "coefs_all = pd.DataFrame(columns=['Coef','p-value','vars','ID','data','predictors_set','randomstate','testsize'])\n",
    "overall_eva_all = pd.DataFrame(columns=['R2','R2-adj','Fvalue','Fpvalue','AIC','BIC',\n",
    "                                        'ID','data','predictors_set','randomstate','testsize'])\n",
    "\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load the data\n",
    "    if spec[0]=='drop':\n",
    "        dat=dat1_drop_missing\n",
    "    else:\n",
    "        dat=dat1_with_missing\n",
    "    # load predictor variables\n",
    "    predictors=spec[1]\n",
    "    # load test size\n",
    "    ts=spec[3]\n",
    "    # load random state\n",
    "    rs=spec[2]\n",
    "    # split data if test size > 0\n",
    "    if ts==0:\n",
    "        X=dat\n",
    "        Y=dat['performance']\n",
    "    else:\n",
    "        sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "        X=sdat1\n",
    "        Y=sdat1['performance']\n",
    "    model=_alg_linear(X,Y,predictors)\n",
    "    coefs=model[0]\n",
    "    overall_eva=model[1]\n",
    "    coefs['ID']=i\n",
    "    coefs['data']=spec[0]\n",
    "    coefs['predictors_set']=len(predictors)\n",
    "    coefs['randomstate']=rs\n",
    "    coefs['testsize']=ts\n",
    "    overall_eva['ID']=i\n",
    "    overall_eva['data']=spec[0]\n",
    "    overall_eva['predictors_set']=len(predictors)\n",
    "    overall_eva['randomstate']=rs\n",
    "    overall_eva['testsize']=ts\n",
    "    coefs_all = pd.concat([coefs_all,coefs],ignore_index=True)\n",
    "    overall_eva_all = pd.concat([overall_eva_all,overall_eva],ignore_index=True)\n",
    "    \n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-TeamPersonality-Coefs-Subset.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  coefs_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-TeamPersonality-ModelEva-Train-Subset.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  overall_eva_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['testsize']==0.4) & (overall_eva_all['data']=='drop')]['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['testsize']==0.4) & (overall_eva_all['data']=='drop')]['R2-adj']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate over different subsets and calculate accuracy on the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors_set=[['open_all_mean'],['extr_all_mean'],\n",
    "                ['extr_all_mean','open_all_mean'],\n",
    "                ['emos_all_mean','extr_all_mean','open_all_mean', 'agree_all_mean', 'cons_all_mean']]\n",
    "data_set=['drop','full']\n",
    "randomstate_list=list(range(1,101))\n",
    "testsize=[0.5,0.4,0.3,0.2]\n",
    "combinations=list(itertools.product(data_set,predictors_set,randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "\n",
    "## create empty full data\n",
    "accuracy_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','predictors_set','randomstate','testsize'])\n",
    "\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load the data\n",
    "    if spec[0]=='drop':\n",
    "        dat=dat1_drop_missing\n",
    "    else:\n",
    "        dat=dat1_with_missing\n",
    "    # load predictor variables\n",
    "    predictors=spec[1]\n",
    "    # load test size\n",
    "    ts=spec[3]\n",
    "    # load random state\n",
    "    rs=spec[2]\n",
    "    # split data\n",
    "    sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "    X_train=sdat1[predictors]\n",
    "    Y_train=sdat1['performance']\n",
    "    X_test=sdat2[predictors]\n",
    "    Y_test=sdat2['performance']\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred=model.predict(X_test)\n",
    "    accuracy = pd.DataFrame({'R2':r2_score(Y_test,Y_pred),\n",
    "                             'MAE':mean_absolute_error(Y_test,Y_pred),\n",
    "                             'RMSE':np.sqrt(mean_squared_error(Y_test, Y_pred))},index=[0])\n",
    "    accuracy['ID']=i\n",
    "    accuracy['data']=spec[0]\n",
    "    accuracy['predictors_set']=len(predictors)\n",
    "    accuracy['randomstate']=rs\n",
    "    accuracy['testsize']=ts\n",
    "    accuracy_all = pd.concat([accuracy_all,accuracy],ignore_index=True)\n",
    "    \n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-TeamPersonality-ModelEva-Test-Subset.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  accuracy_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=accuracy_all[(accuracy_all['testsize']==0.4) & (accuracy_all['data']=='drop')]['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAjQbic3qtuB"
   },
   "source": [
    "## Effect's of leader's personality scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTH4Ymf1sHi_"
   },
   "source": [
    "### With all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1672901749717,
     "user": {
      "displayName": "Nghi Truong",
      "userId": "16652552820501542091"
     },
     "user_tz": -420
    },
    "id": "fEgd-koVsMTf",
    "outputId": "79573c10-051f-477a-bc1f-5e860535a250"
   },
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors_set=[['open_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['agree_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['cons_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['emos_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['extr_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['open_leader','agree_leader','cons_leader','emos_leader','extr_leader',\n",
    "                 'emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean']]\n",
    "data_set=['drop','full']\n",
    "combinations=list(itertools.product(data_set,predictors_set))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "\n",
    "## create empty full data\n",
    "coefs_all = pd.DataFrame(columns=['Coef','p-value','vars','ID','data','predictors_set'])\n",
    "overall_eva_all = pd.DataFrame(columns=['R2','R2-adj','Fvalue','Fpvalue','AIC','BIC',\n",
    "                                        'ID','data','predictors_set'])\n",
    "\n",
    "## run the models\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load the data\n",
    "    if spec[0]=='drop':\n",
    "        dat=dat1_drop_missing\n",
    "    else:\n",
    "        dat=dat1_with_missing\n",
    "    # load predictor variables\n",
    "    predictors=spec[1]\n",
    "    # create X and Y\n",
    "    X=dat\n",
    "    Y=dat['performance']\n",
    "    # run the model\n",
    "    model=_alg_linear(X,Y,predictors)\n",
    "    # get coefs and evaluation indices\n",
    "    coefs=model[0]\n",
    "    overall_eva=model[1]\n",
    "    # add model specification\n",
    "    coefs['ID']=i\n",
    "    coefs['data']=spec[0]\n",
    "    coefs['predictors_set']=len(predictors)\n",
    "    overall_eva['ID']=i\n",
    "    overall_eva['data']=spec[0]\n",
    "    overall_eva['predictors_set']=len(predictors)\n",
    "    # add to the full data\n",
    "    coefs_all = pd.concat([coefs_all,coefs],ignore_index=True)\n",
    "    overall_eva_all = pd.concat([overall_eva_all,overall_eva],ignore_index=True)\n",
    "\n",
    "## save results\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-LeaderPersonality-Coefs-AllObs.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  coefs_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-LeaderPersonality-ModelEva-AllObs.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  overall_eva_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['data']=='drop')]['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['data']=='drop')]['R2-adj']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate over different subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors_set=[['open_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['agree_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['cons_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['emos_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['extr_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['open_leader','agree_leader','cons_leader','emos_leader','extr_leader',\n",
    "                 'emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean']]\n",
    "data_set=['drop','full']\n",
    "randomstate_list=list(range(1,101))\n",
    "testsize=[0.5,0.4,0.3,0.2]\n",
    "combinations=list(itertools.product(data_set,predictors_set,randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "\n",
    "## create empty full data\n",
    "coefs_all = pd.DataFrame(columns=['Coef','p-value','vars','ID','data','predictors_set','randomstate','testsize'])\n",
    "overall_eva_all = pd.DataFrame(columns=['R2','R2-adj','Fvalue','Fpvalue','AIC','BIC',\n",
    "                                        'ID','data','predictors_set','randomstate','testsize'])\n",
    "\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load the data\n",
    "    if spec[0]=='drop':\n",
    "        dat=dat1_drop_missing\n",
    "    else:\n",
    "        dat=dat1_with_missing\n",
    "    # load predictor variables\n",
    "    predictors=spec[1]\n",
    "    # load test size\n",
    "    ts=spec[3]\n",
    "    # load random state\n",
    "    rs=spec[2]\n",
    "    # split data if test size > 0\n",
    "    if ts==0:\n",
    "        X=dat\n",
    "        Y=dat['performance']\n",
    "    else:\n",
    "        sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "        X=sdat1\n",
    "        Y=sdat1['performance']\n",
    "    model=_alg_linear(X,Y,predictors)\n",
    "    coefs=model[0]\n",
    "    overall_eva=model[1]\n",
    "    coefs['ID']=i\n",
    "    coefs['data']=spec[0]\n",
    "    coefs['predictors_set']=len(predictors)\n",
    "    coefs['randomstate']=rs\n",
    "    coefs['testsize']=ts\n",
    "    overall_eva['ID']=i\n",
    "    overall_eva['data']=spec[0]\n",
    "    overall_eva['predictors_set']=len(predictors)\n",
    "    overall_eva['randomstate']=rs\n",
    "    overall_eva['testsize']=ts\n",
    "    coefs_all = pd.concat([coefs_all,coefs],ignore_index=True)\n",
    "    overall_eva_all = pd.concat([overall_eva_all,overall_eva],ignore_index=True)\n",
    "    \n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-LeaderPersonality_Coefs-Subset.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  coefs_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-LeaderPersonality-ModelEva-Train-Subset.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  overall_eva_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['testsize']==0.4) & (overall_eva_all['data']=='drop')]['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=overall_eva_all[(overall_eva_all['testsize']==0.4) & (overall_eva_all['data']=='drop')]['R2-adj']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate over different subsets and calculate accuracy on the test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors_set=[['open_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['agree_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['cons_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['emos_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['extr_leader','emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean'],\n",
    "                ['open_leader','agree_leader','cons_leader','emos_leader','extr_leader',\n",
    "                 'emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean']]\n",
    "data_set=['drop','full']\n",
    "randomstate_list=list(range(1,101))\n",
    "testsize=[0.5,0.4,0.3,0.2]\n",
    "combinations=list(itertools.product(data_set,predictors_set,randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "\n",
    "## create empty full data\n",
    "accuracy_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','predictors_set','randomstate','testsize'])\n",
    "\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load the data\n",
    "    if spec[0]=='drop':\n",
    "        dat=dat1_drop_missing\n",
    "    else:\n",
    "        dat=dat1_with_missing\n",
    "    # load predictor variables\n",
    "    predictors=spec[1]\n",
    "    # load test size\n",
    "    ts=spec[3]\n",
    "    # load random state\n",
    "    rs=spec[2]\n",
    "    # split data\n",
    "    sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "    X_train=sdat1[predictors]\n",
    "    Y_train=sdat1['performance']\n",
    "    X_test=sdat2[predictors]\n",
    "    Y_test=sdat2['performance']\n",
    "    model=LinearRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "    Y_pred=model.predict(X_test)\n",
    "    accuracy = pd.DataFrame({'R2':r2_score(Y_test,Y_pred),\n",
    "                             'MAE':mean_absolute_error(Y_test,Y_pred),\n",
    "                             'RMSE':np.sqrt(mean_squared_error(Y_test, Y_pred))},index=[0])\n",
    "    accuracy['ID']=i\n",
    "    accuracy['data']=spec[0]\n",
    "    accuracy['predictors_set']=len(predictors)\n",
    "    accuracy['randomstate']=rs\n",
    "    accuracy['testsize']=ts\n",
    "    accuracy_all = pd.concat([accuracy_all,accuracy],ignore_index=True)\n",
    "    \n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-TestHyp-LeaderPersonality-ModelEva-Test-Subset.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "  accuracy_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=accuracy_all[(accuracy_all['testsize']==0.4) & (accuracy_all['data']=='drop')]['R2']\n",
    "sns.boxplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithm -- allow for non-linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Drop Data - splitting: 60/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors=['emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean', 'emos_exc_sd',\n",
    "            'extr_exc_sd', 'open_exc_sd', 'agree_exc_sd', 'cons_exc_sd','gender_exc_mean', 'gender_leader',\n",
    "            'emos_leader', 'extr_leader', 'open_leader', 'agree_leader','cons_leader']\n",
    "randomstate_list=list(range(1,101))\n",
    "#testsize=[0.5,0.4,0.3,0.2]\n",
    "testsize=[0.4]\n",
    "combinations=list(itertools.product(randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "# params for random forest\n",
    "params = {'n_estimators': [10,50,100,200,300],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': [3,5,10,50,80,100],\n",
    "               'min_samples_split': [4, 6, 8, 10,12],\n",
    "               'min_samples_leaf': [3,4,5,8,10],\n",
    "               'bootstrap': [True, False]}\n",
    "cv=5\n",
    "n_iter=200\n",
    "\n",
    "## load data\n",
    "dat=dat1_drop_missing\n",
    "\n",
    "## create empty full data\n",
    "features_all = pd.DataFrame(columns=['feature','score','ID','data','randomstate','testsize'])\n",
    "evaluationA_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','randomstate','testsize'])\n",
    "evaluationB_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','randomstate','testsize'])\n",
    "best_params_all = pd.DataFrame(columns=['n_estimators','min_samples_split','min_samples_leaf','max_features','max_depth','bootstrap',\n",
    "                                        'ID','data','randomstate','testsize'])\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load random state and test size\n",
    "    rs=spec[0]\n",
    "    ts=spec[1]\n",
    "    # split data\n",
    "    sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "    X_train=sdat1[predictors]\n",
    "    Y_train=sdat1['performance']\n",
    "    X_test=sdat2[predictors]\n",
    "    Y_test=sdat2['performance']\n",
    "    # train model\n",
    "    model=_alg_randomforest(X_train,Y_train,X_test,Y_test,params,cv,n_iter)\n",
    "    features=model[0]\n",
    "    features['ID']=i\n",
    "    features['data']='drop'\n",
    "    features['randomstate']=rs\n",
    "    features['testsize']=ts\n",
    "    features_all = pd.concat([features_all,features],ignore_index=True)\n",
    "    evaluationA=model[1]\n",
    "    evaluationA['ID']=i\n",
    "    evaluationA['data']='drop'\n",
    "    evaluationA['randomstate']=rs\n",
    "    evaluationA['testsize']=ts\n",
    "    evaluationA_all = pd.concat([evaluationA_all,evaluationA],ignore_index=True)\n",
    "    evaluationB=model[2]\n",
    "    evaluationB['ID']=i\n",
    "    evaluationB['data']='drop'\n",
    "    evaluationB['randomstate']=rs\n",
    "    evaluationB['testsize']=ts\n",
    "    evaluationB_all = pd.concat([evaluationB_all,evaluationB],ignore_index=True)\n",
    "    best_params=model[3]\n",
    "    best_params['ID']=i\n",
    "    best_params['data']='drop'\n",
    "    best_params['randomstate']=rs\n",
    "    best_params['testsize']=ts\n",
    "    best_params_all = pd.concat([best_params_all,best_params],ignore_index=True)\n",
    "    \n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-RandomSearch-FeaturesScore-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    features_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-RandomSearch-ModelEval-Train-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    evaluationA_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-RandomSearch-ModelEval-Test-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    evaluationB_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-RandomSearch-BestParams-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    best_params_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=evaluationA_all['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=evaluationB_all['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check parameters\n",
    "for col in best_params_all:\n",
    "  print(best_params_all[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the importance score of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Drop Data - splitting: 60/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors=['emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean', 'emos_exc_sd',\n",
    "            'extr_exc_sd', 'open_exc_sd', 'agree_exc_sd', 'cons_exc_sd','gender_exc_mean', 'gender_leader',\n",
    "            'emos_leader', 'extr_leader', 'open_leader', 'agree_leader','cons_leader']\n",
    "randomstate_list=list(range(1,101))\n",
    "#testsize=[0.5,0.4,0.3,0.2]\n",
    "testsize=[0.4]\n",
    "combinations=list(itertools.product(randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "# params for random forest\n",
    "params = {'bootstrap': [True],\n",
    "              'max_depth': [3,5,80],   # 90, 100\n",
    "              'max_features': ['sqrt'],    # [2,3,4,5,6]\n",
    "              'min_samples_leaf': [3, 5, 8,10],\n",
    "              'min_samples_split': [4,6,8,10,12],\n",
    "              'n_estimators': [50, 100, 200]}\n",
    "cv=5\n",
    "\n",
    "## load data\n",
    "dat=dat1_drop_missing\n",
    "\n",
    "## create empty full data\n",
    "features_all = pd.DataFrame(columns=['feature','score','ID','data','randomstate','testsize'])\n",
    "evaluationA_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','randomstate','testsize'])\n",
    "evaluationB_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','randomstate','testsize'])\n",
    "best_params_all = pd.DataFrame(columns=['n_estimators','min_samples_split','min_samples_leaf','max_features','max_depth','bootstrap',\n",
    "                                        'ID','data','randomstate','testsize'])\n",
    "\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load random state and test size\n",
    "    rs=spec[0]\n",
    "    ts=spec[1]\n",
    "    # split data\n",
    "    sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "    X_train=sdat1[predictors]\n",
    "    Y_train=sdat1['performance']\n",
    "    X_test=sdat2[predictors]\n",
    "    Y_test=sdat2['performance']\n",
    "    # train model\n",
    "    model=_alg_randomforest_gridsearch(X_train,Y_train,X_test,Y_test,params,cv)\n",
    "    features=model[0]\n",
    "    features['ID']=i\n",
    "    features['data']='drop'\n",
    "    features['randomstate']=rs\n",
    "    features['testsize']=ts\n",
    "    features_all = pd.concat([features_all,features],ignore_index=True)\n",
    "    evaluationA=model[1]\n",
    "    evaluationA['ID']=i\n",
    "    evaluationA['data']='drop'\n",
    "    evaluationA['randomstate']=rs\n",
    "    evaluationA['testsize']=ts\n",
    "    evaluationA_all = pd.concat([evaluationA_all,evaluationA],ignore_index=True)\n",
    "    evaluationB=model[2]\n",
    "    evaluationB['ID']=i\n",
    "    evaluationB['data']='drop'\n",
    "    evaluationB['randomstate']=rs\n",
    "    evaluationB['testsize']=ts\n",
    "    evaluationB_all = pd.concat([evaluationB_all,evaluationB],ignore_index=True)\n",
    "    best_params=model[3]\n",
    "    best_params['ID']=i\n",
    "    best_params['data']='drop'\n",
    "    best_params['randomstate']=rs\n",
    "    best_params['testsize']=ts\n",
    "    best_params_all = pd.concat([best_params_all,best_params],ignore_index=True)\n",
    "    \n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-FeaturesScore-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    features_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-ModelEval-Train-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    evaluationA_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-ModelEval-Test-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    evaluationB_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-BestParams-DropData-6040.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    best_params_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=evaluationA_all['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=evaluationB_all['R2']\n",
    "sns.boxplot(x)\n",
    "sns.displot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the importance score of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network + RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the parameters\n",
    "predictors=['emos_exc_mean', 'extr_exc_mean','open_exc_mean', 'agree_exc_mean', 'cons_exc_mean', 'emos_exc_sd',\n",
    "            'extr_exc_sd', 'open_exc_sd', 'agree_exc_sd', 'cons_exc_sd','gender_exc_mean', 'gender_leader',\n",
    "            'emos_leader', 'extr_leader', 'open_leader', 'agree_leader','cons_leader']\n",
    "randomstate_list=list(range(1,101))\n",
    "#testsize=[0.5,0.4,0.3,0.2]\n",
    "testsize=[0.4]\n",
    "combinations=list(itertools.product(randomstate_list,testsize))\n",
    "#spec_data=pd.DataFrame(combinations, columns=['data', 'predictors', 'randomstate','testsize'])\n",
    "# params for random forest\n",
    "params = {'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "          'solver' : ['lbfgs', 'sgd', 'adam'],\n",
    "          'hidden_layer_sizes' : [(17,15,10,5,2),(17,14,10,5,2),(16,12,8,4,2)],\n",
    "          'max_iter' : [2000]}\n",
    "#params = {'activation' : ['identity', 'logistic', 'tanh', 'relu'],\n",
    "#          'solver' : ['lbfgs', 'adam'],\n",
    "#          'hidden_layer_sizes' : [(100,50,25),(200,100,50)],\n",
    "#          'learning_rate_init' : scipy.stats.uniform(0.001, 0.005),\n",
    "#          'max_iter' : scipy.stats.randint(200,2000)}\n",
    "cv=5\n",
    "n_iter=200\n",
    "rs=123456\n",
    "ts=0.4\n",
    "## load data\n",
    "dat=dat1_drop_missing\n",
    "\n",
    "## create empty full data\n",
    "evaluationA_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','randomstate','testsize'])\n",
    "evaluationB_all = pd.DataFrame(columns=['R2','MAE','RMSE','ID','data','randomstate','testsize'])\n",
    "best_params_all = pd.DataFrame(columns=['solver','max_iter','hidden_layer_sizes','activation',\n",
    "                                        'ID','data','randomstate','testsize'])\n",
    "\n",
    "for i in list(range(0,len(combinations))):\n",
    "    # get the specifications\n",
    "    spec=combinations[i]\n",
    "    # load random state and test size\n",
    "    rs=spec[0]\n",
    "    ts=spec[1]\n",
    "    # split data\n",
    "    sdat1,sdat2=train_test_split(dat,test_size=ts,random_state=rs)\n",
    "    X_train=sdat1[predictors]\n",
    "    Y_train=sdat1['performance']\n",
    "    X_test=sdat2[predictors]\n",
    "    Y_test=sdat2['performance']\n",
    "    # train model\n",
    "    model=_alg_NeuralNetwork_RandomizedSearch(X_train,Y_train,X_test,Y_test,params,cv,n_iter,False)\n",
    "    evaluationA=model[0]\n",
    "    evaluationA['ID']=i\n",
    "    evaluationA['data']='drop'\n",
    "    evaluationA['randomstate']=rs\n",
    "    evaluationA['testsize']=ts\n",
    "    evaluationA_all = pd.concat([evaluationA_all,evaluationA],ignore_index=True)\n",
    "    evaluationB=model[1]\n",
    "    evaluationB\n",
    "    evaluationB['ID']=i\n",
    "    evaluationB['data']='drop'\n",
    "    evaluationB['randomstate']=rs\n",
    "    evaluationB['testsize']=ts\n",
    "    evaluationB_all = pd.concat([evaluationB_all,evaluationB],ignore_index=True)\n",
    "    best_params=model[2]\n",
    "    best_params['ID']=i\n",
    "    best_params['data']='drop'\n",
    "    best_params['randomstate']=rs\n",
    "    best_params['testsize']=ts\n",
    "    best_params_all = pd.concat([best_params_all,best_params],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>randomstate</th>\n",
       "      <th>testsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.219541e-02</td>\n",
       "      <td>114.087642</td>\n",
       "      <td>144.536549</td>\n",
       "      <td>0</td>\n",
       "      <td>drop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.241851e-13</td>\n",
       "      <td>114.640684</td>\n",
       "      <td>143.690210</td>\n",
       "      <td>1</td>\n",
       "      <td>drop</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.009818e-10</td>\n",
       "      <td>115.958649</td>\n",
       "      <td>146.622481</td>\n",
       "      <td>2</td>\n",
       "      <td>drop</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.230716e-02</td>\n",
       "      <td>112.958936</td>\n",
       "      <td>140.849495</td>\n",
       "      <td>3</td>\n",
       "      <td>drop</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.633671e-02</td>\n",
       "      <td>115.680257</td>\n",
       "      <td>147.468010</td>\n",
       "      <td>4</td>\n",
       "      <td>drop</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3.243266e-02</td>\n",
       "      <td>115.914110</td>\n",
       "      <td>146.676113</td>\n",
       "      <td>95</td>\n",
       "      <td>drop</td>\n",
       "      <td>96</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-2.185142e-02</td>\n",
       "      <td>114.396903</td>\n",
       "      <td>144.227679</td>\n",
       "      <td>96</td>\n",
       "      <td>drop</td>\n",
       "      <td>97</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.175720e-08</td>\n",
       "      <td>110.717724</td>\n",
       "      <td>139.601294</td>\n",
       "      <td>97</td>\n",
       "      <td>drop</td>\n",
       "      <td>98</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-1.690525e-01</td>\n",
       "      <td>120.370965</td>\n",
       "      <td>150.695406</td>\n",
       "      <td>98</td>\n",
       "      <td>drop</td>\n",
       "      <td>99</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-1.827427e-13</td>\n",
       "      <td>114.908743</td>\n",
       "      <td>143.547100</td>\n",
       "      <td>99</td>\n",
       "      <td>drop</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              R2         MAE        RMSE  ID  data randomstate  testsize\n",
       "0   3.219541e-02  114.087642  144.536549   0  drop           1       0.4\n",
       "1  -3.241851e-13  114.640684  143.690210   1  drop           2       0.4\n",
       "2   5.009818e-10  115.958649  146.622481   2  drop           3       0.4\n",
       "3   1.230716e-02  112.958936  140.849495   3  drop           4       0.4\n",
       "4  -1.633671e-02  115.680257  147.468010   4  drop           5       0.4\n",
       "..           ...         ...         ...  ..   ...         ...       ...\n",
       "95  3.243266e-02  115.914110  146.676113  95  drop          96       0.4\n",
       "96 -2.185142e-02  114.396903  144.227679  96  drop          97       0.4\n",
       "97  2.175720e-08  110.717724  139.601294  97  drop          98       0.4\n",
       "98 -1.690525e-01  120.370965  150.695406  98  drop          99       0.4\n",
       "99 -1.827427e-13  114.908743  143.547100  99  drop         100       0.4\n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluationA_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-ModelEval-Train-DropData-6040_test4.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    evaluationA_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-ModelEval-Test-DropData-6040-test4.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    evaluationB_all.to_csv(f)\n",
    "path=\"D:/ResearchProjects/Phanish-Tianyu-5Personality/Results/Jan06/TeamPersonality-Jan06-RandomForest-GridSearch-BestParams-DropData-6040-test4.csv\"\n",
    "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "    best_params_all.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='R2'>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=evaluationA_all['R2']\n",
    "sns.boxplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='R2'>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=evaluationB_all['R2']\n",
    "sns.boxplot(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>activation</th>\n",
       "      <th>ID</th>\n",
       "      <th>data</th>\n",
       "      <th>randomstate</th>\n",
       "      <th>testsize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>17,10,5,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>drop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>17,10,5,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>drop</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>17,10,5,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>drop</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>17,10,5,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>drop</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>16,8,4,2</td>\n",
       "      <td>logistic</td>\n",
       "      <td>4</td>\n",
       "      <td>drop</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>16,8,4,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>95</td>\n",
       "      <td>drop</td>\n",
       "      <td>96</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>16,8,4,2</td>\n",
       "      <td>logistic</td>\n",
       "      <td>96</td>\n",
       "      <td>drop</td>\n",
       "      <td>97</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>16,8,4,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>97</td>\n",
       "      <td>drop</td>\n",
       "      <td>98</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>2000</td>\n",
       "      <td>17,12,8,4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>98</td>\n",
       "      <td>drop</td>\n",
       "      <td>99</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>sgd</td>\n",
       "      <td>2000</td>\n",
       "      <td>17,10,5,2</td>\n",
       "      <td>tanh</td>\n",
       "      <td>99</td>\n",
       "      <td>drop</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   solver max_iter hidden_layer_sizes activation  ID  data randomstate  \\\n",
       "0     sgd     2000          17,10,5,2       tanh   0  drop           1   \n",
       "1     sgd     2000          17,10,5,2       tanh   1  drop           2   \n",
       "2     sgd     2000          17,10,5,2       tanh   2  drop           3   \n",
       "3     sgd     2000          17,10,5,2       tanh   3  drop           4   \n",
       "4     sgd     2000           16,8,4,2   logistic   4  drop           5   \n",
       "..    ...      ...                ...        ...  ..   ...         ...   \n",
       "95    sgd     2000           16,8,4,2       tanh  95  drop          96   \n",
       "96    sgd     2000           16,8,4,2   logistic  96  drop          97   \n",
       "97    sgd     2000           16,8,4,2       tanh  97  drop          98   \n",
       "98  lbfgs     2000          17,12,8,4       tanh  98  drop          99   \n",
       "99    sgd     2000          17,10,5,2       tanh  99  drop         100   \n",
       "\n",
       "    testsize  \n",
       "0        0.4  \n",
       "1        0.4  \n",
       "2        0.4  \n",
       "3        0.4  \n",
       "4        0.4  \n",
       "..       ...  \n",
       "95       0.4  \n",
       "96       0.4  \n",
       "97       0.4  \n",
       "98       0.4  \n",
       "99       0.4  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgLsUSKUV2DlJlHt+aYMMf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
