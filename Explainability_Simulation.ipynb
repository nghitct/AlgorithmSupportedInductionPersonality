{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/XjVa/4UM9q2p3KC8darp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nghitct/AlgorithmSupportedInductionPersonality/blob/main/Explainability_Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co_glqBrbAlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb587e9a-62c3-4d70-ab94-230029438928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#import basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#warnings.filterwarnings(action='once')\n",
        "from itertools import combinations, product\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "import networkx as nx \n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function for generating graph: \n",
        "# gtype: type of graph, can be 'random' (Erdos-Renyi model with n nodes and prob p),\n",
        "# 'smallworld' (Watts Strogatz model with n nodes, k mean degrees and beta),\n",
        "# 'scalefree' (power law graph by Barabasi Albert model with n nodes and m \n",
        "# number of edges to attach from a new node to existing node), \n",
        "# 'clusteredscalefree' (Holme Kim model for power law graph with approximate average clustering)\n",
        "\n",
        "def _gen_graph(gtype,gparams):\n",
        "  # Erdos Renyi random graph\n",
        "  if gtype=='random':\n",
        "    G=nx.erdos_renyi_graph(gparams['n'],gparams['p'])\n",
        "  # Watts Strogatz small world graph\n",
        "  elif gtype=='smallworld':\n",
        "    G=nx.watts_strogatz_graph(gparams['n'],gparams['k'],gparams['beta'])\n",
        "  # Barabasi Albert scale free graph\n",
        "  elif gtype=='scalefree':\n",
        "    G=nx.barabasi_albert_graph(gparams['n'],gparams['m'])\n",
        "  # clustered scale free graph\n",
        "  elif gtype=='clusteredscalefree':\n",
        "    G=nx.powerlaw_cluster_graph(gparams['n'],gparams['m'],gparams['p'])\n",
        "  else:\n",
        "    G=nx.empty_graph(gparams['n'])\n",
        "    print('type error')\n",
        "  # remove loop and parallel edges\n",
        "  G.remove_edges_from(nx.selfloop_edges(G))\n",
        "  G=nx.Graph(G)\n",
        "  return G\n",
        "\n",
        "#function for selecting explanatory nodes K (overlapping nodes):\n",
        "# spec includes 'type' and 'measure'; G: explainer's graph; k: size of K\n",
        "# nodes can be selected randomly ('type'='random') or proportionally to some\n",
        "# network measures ('type'='central') or inversely proportionally ('type'='invcentral').\n",
        "# 4 types of measures: 'degree', 'closeness', 'pagerank', 'betweenness'\n",
        "\n",
        "def _sel_exp_nodes(spec,G,k,seed):\n",
        "  gen = np.random.RandomState(seed)\n",
        "  # pick node randomly\n",
        "  if spec['type']=='random':\n",
        "    K=gen.choice(list(G.nodes),k,replace=False)\n",
        "  # pick node proportionally to central measures\n",
        "  elif spec['type']=='central':\n",
        "    # degree measure\n",
        "    if spec['measure']=='degree':\n",
        "      c=[x[1] for x in G.degree()]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    # pagerank centrality\n",
        "    elif spec['measure']=='pagerank':\n",
        "      c=[x for x in nx.pagerank_numpy(G,alpha=0.75)]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    # closeness centrality\n",
        "    elif spec['measure']=='closeness':\n",
        "      c=[x for x in nx.closeness_centrality(G).values()]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    # betweenness centrality\n",
        "    elif spec['measure']=='betweenness':\n",
        "      c=[x for x in nx.betweenness_centrality(G).values()]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    else:\n",
        "      K=list()\n",
        "      print('measure error')\n",
        "  # pick node inversely proportionally to central measures\n",
        "  elif spec['type']=='invcentral':\n",
        "    # degree measure\n",
        "    if spec['measure']=='degree':\n",
        "      c=[1/x[1] if x[1]!=0 else 0 for x in G.degree()]    \n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    # pagerank centrality\n",
        "    elif spec['measure']=='pagerank':\n",
        "      c=[1/x if x!=0 else 0 for x in nx.pagerank_numpy(G,alpha=0.75)]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    # closeness centrality\n",
        "    elif spec['measure']=='closeness':\n",
        "      c=[1/x if x!=0 else 0 for x in nx.closeness_centrality(G).values()]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    # betweenness centrality\n",
        "    elif spec['measure']=='betweenness':\n",
        "      c=[1/x if x!=0 else 0 for x in nx.betweenness_centrality(G).values()]\n",
        "      p=[x/sum(c) for x in c]\n",
        "      K=gen.choice(list(G.nodes),k,replace=False,p=p)\n",
        "    else:\n",
        "      K=list()\n",
        "      print('measure error')\n",
        "  else:\n",
        "    K=list()\n",
        "    print('type error')\n",
        "  return K\n",
        "\n",
        "#function to generate search list: list of nodes to search for one node \n",
        "#to reveal to explainee at each trial\n",
        "# G: explainer's graph; target node: node to be explained;\n",
        "# level: level of ego-network of target node for searching;\n",
        "# expl_path: nodes already revealed to explainee\n",
        "\n",
        "def _gen_search_list (G,target_node,level,expl_path):\n",
        "  # get all nodes in the l-level ego graph of the target node\n",
        "  full_search_list=list(nx.ego_graph(G,target_node,radius=level).nodes)\n",
        "  # remove nodes that are already revealed to explainee (nodes in explaining path)\n",
        "  search_list=list(set(full_search_list).symmetric_difference(set(expl_path)))\n",
        "  return search_list\n",
        "\n",
        "#function to select one node in the searh list\n",
        "# search_list: list of nodes to search for one node to reveal to explainee;\n",
        "# G: explainer's graph; target node: node to be explained;\n",
        "# behavior: 0: choose randomly, 1: choose proportionally to the number of shortest\n",
        "# paths between the target node and nodes in the search list \n",
        "def _choose_trial(search_list,G,target_node,behavior,seed):\n",
        "  gen = np.random.RandomState(seed)\n",
        "  # choose randomly (and uniformly)\n",
        "  if behavior == 0:\n",
        "    trial = gen.choice(search_list)\n",
        "  # nodes with more shortest paths to the target node \n",
        "  # will have higher probability of being selected\n",
        "  elif behavior == 1:\n",
        "    # get numbers of shortest paths from the target node to nodes in the search list\n",
        "    p=[len(list(nx.all_shortest_paths(G,R0,x))) for x in search_list]\n",
        "    # turn to probablity\n",
        "    p=[x/sum(p) for x in p]\n",
        "    # choose nodes with probability p\n",
        "    trial = gen.choice(search_list,p=p)\n",
        "  return trial\n",
        "\n",
        "#function for search process\n",
        "# G: explainer's graph, target_node: node to be explained; behavior: 0 or 1\n",
        "# rule: \n",
        "def _search_process (G,target_node,behavior,seed):\n",
        "  # initial values\n",
        "  not_explain=True\n",
        "  not_exhaus=True\n",
        "  expl_path=list()\n",
        "  level=0\n",
        "\n",
        "  # find the highest radius of the ego network of the target node\n",
        "  max_radius=max(nx.single_source_shortest_path_length(G,target_node).values())\n",
        "\n",
        "  # when explainability has not been achieved and not all nodes in the (largest)\n",
        "  # target node's ego graph are revealed:\n",
        "  while not_explain and not_exhaus:\n",
        "    # generate search list\n",
        "    search_list=_gen_search_list(G,target_node,level,expl_path)\n",
        "    # pick one node in the search list\n",
        "    trial=_choose_trial(search_list,G,target_node,behavior,seed)\n",
        "    # if trial is in the explanatory set K: \n",
        "    # explainability is achieved -> not_explain = True\n",
        "    if trial in K:\n",
        "      expl_path.append(trial)\n",
        "      not_explain=False\n",
        "    # if trial is not in the explanatory set K:\n",
        "    else:\n",
        "      # add trial to the explaining path expl_path:\n",
        "      expl_path.append(trial)\n",
        "      # remove trial out of the search list:\n",
        "      search_list.remove(trial)\n",
        "      # if the search list is empty (all nodes in the search list are revealed)\n",
        "      if len(search_list)==0:\n",
        "        # if we still have othe levels to search (level<max_radius): move one level up\n",
        "        if level<max_radius:\n",
        "          level=level+1\n",
        "        # if all levels are used: not_exhaus = False\n",
        "        else:\n",
        "          not_exhaus=False\n",
        "\n",
        "  # gen and return results \n",
        "  results={'explain': (not not_explain),\n",
        "         'time': len(expl_path),\n",
        "         'radius': level,\n",
        "         'explain_path': expl_path}\n",
        "  return results\n",
        "\n",
        "def _ave_shortest_path (G):\n",
        "  if nx.is_connected(G):\n",
        "    return(nx.average_shortest_path_length(R))\n",
        "  else:\n",
        "    return(9999)"
      ],
      "metadata": {
        "id": "clISn_fxbNsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round 1: Random graph, random overlap, random search"
      ],
      "metadata": {
        "id": "uc5-DBn8uAre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set parameters"
      ],
      "metadata": {
        "id": "-ijkGnaLA0Mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seed and randomstate\n",
        "seed_list = random.sample(range(1,1000000),1000)\n",
        "\n",
        "#We have a domain S with size N_S, the explainer's graph with size N_R,\n",
        "# the explainee's graph with size N_E and the probability p_K of overlapping nodes\n",
        "# (from the explainer's graph R). If we let N_R and p_K run without any constraint,\n",
        "# we have to ignore N_S and N_E. For domain S, we can assume unlimited domain \n",
        "# (or domain is very large compared with individual knowledge graph). For N_E, we\n",
        "# can assume p_K is the joint probability of both overlapping and size of the \n",
        "# explainee's graph. So in the following codes, we ignore N_S and N_E. If later,\n",
        "# we want to extend the model to incorporate the explainee's graph E or the domain \n",
        "# S (i.e. S is not fully connected as we assume now), we need to add more parameters.\n",
        "\n",
        "#define the explainer's graph\n",
        "N_R_list = list(np.arange(5,105))\n",
        "p_random_list = list(np.arange(0.1,1,0.1))\n",
        "\n",
        "#define the set of explanatory nodes K\n",
        "p_K_list = list(np.arange(0.1,1,0.1))"
      ],
      "metadata": {
        "id": "Bfc0kLX9puvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation"
      ],
      "metadata": {
        "id": "nTgmIL_jA3nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_all=pd.DataFrame(columns=['explain', 'time', 'radius', 'explain_path', 'density', 'ave_sh_path',\n",
        "       'ave_clustering', 'efficient', 'ave_deg', 'size_explainer_graph',\n",
        "       'type_explainer_graph', 'seed', 'type_overlap', 'prop_of_overlap',\n",
        "       'search_behavior'])\n",
        "for N_R in N_R_list:\n",
        "  for p_random in p_random_list:\n",
        "    for seed in seed_list:\n",
        "      random.seed(seed)\n",
        "      #create the explainer's graph\n",
        "      R_params={'gtype': 'random','gparams':{'n': N_R,'p': p_random}}\n",
        "      R = _gen_graph(**R_params)\n",
        "      #calculate the graph properties\n",
        "      R_properties={'density': nx.density(R),\n",
        "                    'ave_sh_path': _ave_shortest_path(R),\n",
        "                    'ave_clustering': nx.average_clustering(R),\n",
        "                    'efficient': nx.global_efficiency(R), \n",
        "                    'ave_deg': sum([x[1] for x in list(R.degree)])/N_R}\n",
        "      \n",
        "      for p_K in p_K_list:\n",
        "        #define K explanatory nodes are chosen from the explainer's knowledge graph\n",
        "        N_K = round(N_R*p_K)\n",
        "        params={'spec': {'type': 'random'},'G': R,'k': N_K, 'seed': seed}\n",
        "        K=_sel_exp_nodes(**params)\n",
        "\n",
        "        #define target node:\n",
        "        gen = np.random.RandomState(seed)\n",
        "        R0=gen.choice(list(R.nodes()))\n",
        "\n",
        "        #produce search results\n",
        "        search_results=_search_process(R,R0,0,seed)\n",
        "\n",
        "        #create data frame\n",
        "        results=pd.concat([pd.DataFrame([search_results]),pd.DataFrame([R_properties])],axis=1)\n",
        "        results['size_explainer_graph']=N_R\n",
        "        results['type_explainer_graph']='random'\n",
        "        results['seed']=seed\n",
        "        results['type_overlap']='random'\n",
        "        results['prop_of_overlap']=p_K\n",
        "        results['search_behavior']=0\n",
        "        \n",
        "        #add to the full data frame\n",
        "        results_all = pd.concat([results_all,results],ignore_index=True)\n",
        "\n",
        "        path=\"/content/gdrive/MyDrive/Colab Notebooks/Expl-RanGr-RanOver-RanSearch-iteration-1228.csv\"\n",
        "        with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "          results_all.to_csv(f)\n",
        "\n",
        "path=\"/content/gdrive/MyDrive/Colab Notebooks/Expl-RanGr-RanOver-RanSearch-1228.csv\"\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  results_all.to_csv(f)"
      ],
      "metadata": {
        "id": "SZVd__Lrwsbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round 2: Random graph, random overlap, search proportional to number of shortest paths"
      ],
      "metadata": {
        "id": "LQsxGS2oBwsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial parameters"
      ],
      "metadata": {
        "id": "hzPhawi2B5fE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seed and randomstate\n",
        "seed_list = random.sample(range(1,1000000),1000)\n",
        "\n",
        "#We have a domain S with size N_S, the explainer's graph with size N_R,\n",
        "# the explainee's graph with size N_E and the probability p_K of overlapping nodes\n",
        "# (from the explainer's graph R). If we let N_R and p_K run without any constraint,\n",
        "# we have to ignore N_S and N_E. For domain S, we can assume unlimited domain \n",
        "# (or domain is very large compared with individual knowledge graph). For N_E, we\n",
        "# can assume p_K is the joint probability of both overlapping and size of the \n",
        "# explainee's graph. So in the following codes, we ignore N_S and N_E. If later,\n",
        "# we want to extend the model to incorporate the explainee's graph E or the domain \n",
        "# S (i.e. S is not fully connected as we assume now), we need to add more parameters.\n",
        "\n",
        "#define the explainer's graph\n",
        "N_R_list = list(np.arange(5,105))\n",
        "p_random_list = list(np.arange(0.1,1,0.1))\n",
        "\n",
        "#define the set of explanatory nodes K\n",
        "p_K_list = list(np.arange(0.1,1,0.1))"
      ],
      "metadata": {
        "id": "31FTF_3QB7Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation"
      ],
      "metadata": {
        "id": "Sy7KBRI_B95A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_all=pd.DataFrame(columns=['explain', 'time', 'radius', 'explain_path', 'density', 'ave_sh_path',\n",
        "       'ave_clustering', 'efficient', 'ave_deg', 'size_explainer_graph',\n",
        "       'type_explainer_graph', 'seed', 'type_overlap', 'prop_of_overlap',\n",
        "       'search_behavior'])\n",
        "for N_R in N_R_list:\n",
        "  for p_random in p_random_list:\n",
        "    for seed in seed_list:\n",
        "      random.seed(seed)\n",
        "      #create the explainer's graph\n",
        "      R_params={'gtype': 'random','gparams':{'n': N_R,'p': p_random}}\n",
        "      R = _gen_graph(**R_params)\n",
        "      #calculate the graph properties\n",
        "      R_properties={'density': nx.density(R),\n",
        "                    'ave_sh_path': _ave_shortest_path(R),\n",
        "                    'ave_clustering': nx.average_clustering(R),\n",
        "                    'efficient': nx.global_efficiency(R), \n",
        "                    'ave_deg': sum([x[1] for x in list(R.degree)])/N_R}\n",
        "      \n",
        "      for p_K in p_K_list:\n",
        "        #define K explanatory nodes are chosen from the explainer's knowledge graph\n",
        "        N_K = round(N_R*p_K)\n",
        "        params={'spec': {'type': 'random'},'G': R,'k': N_K, 'seed': seed}\n",
        "        K=_sel_exp_nodes(**params)\n",
        "\n",
        "        #define target node:\n",
        "        gen = np.random.RandomState(seed)\n",
        "        R0=gen.choice(list(R.nodes()))\n",
        "\n",
        "        #produce search results\n",
        "        search_results=_search_process(R,R0,0,seed)\n",
        "\n",
        "        #create data frame\n",
        "        results=pd.concat([pd.DataFrame([search_results]),pd.DataFrame([R_properties])],axis=1)\n",
        "        results['size_explainer_graph']=N_R\n",
        "        results['type_explainer_graph']='random'\n",
        "        results['seed']=seed\n",
        "        results['type_overlap']='random'\n",
        "        results['prop_of_overlap']=p_K\n",
        "        results['search_behavior']=1\n",
        "        \n",
        "        #add to the full data frame\n",
        "        results_all = pd.concat([results_all,results],ignore_index=True)\n",
        "\n",
        "path=\"/content/gdrive/MyDrive/Colab Notebooks/Expl-RanGr-RanOver-PropSearch-1224.csv\"\n",
        "with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
        "  results_all.to_csv(f)"
      ],
      "metadata": {
        "id": "vOp2N1JRB_AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Round 3: Small World graph, random overlap, random search"
      ],
      "metadata": {
        "id": "Dakgm2PcCHai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial parameters"
      ],
      "metadata": {
        "id": "l3Jq8CT7COO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seed and randomstate\n",
        "seed_list = random.sample(range(1,1000000),1000)\n",
        "\n",
        "#We have a domain S with size N_S, the explainer's graph with size N_R,\n",
        "# the explainee's graph with size N_E and the probability p_K of overlapping nodes\n",
        "# (from the explainer's graph R). If we let N_R and p_K run without any constraint,\n",
        "# we have to ignore N_S and N_E. For domain S, we can assume unlimited domain \n",
        "# (or domain is very large compared with individual knowledge graph). For N_E, we\n",
        "# can assume p_K is the joint probability of both overlapping and size of the \n",
        "# explainee's graph. So in the following codes, we ignore N_S and N_E. If later,\n",
        "# we want to extend the model to incorporate the explainee's graph E or the domain \n",
        "# S (i.e. S is not fully connected as we assume now), we need to add more parameters.\n",
        "\n",
        "#define the explainer's graph\n",
        "N_R_list = list(np.arange(5,105))\n",
        "p_random_list = list(np.arange(0.1,1,0.1))\n",
        "\n",
        "#define the set of explanatory nodes K\n",
        "p_K_list = list(np.arange(0.1,1,0.1))"
      ],
      "metadata": {
        "id": "VzrcqREJCPpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation"
      ],
      "metadata": {
        "id": "MwAGtlKXCShF"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-jn-OTQCW5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}